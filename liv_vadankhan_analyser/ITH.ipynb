{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "\n",
    "CURRENT_DIR = Path(os.getcwd())\n",
    "# Move to the root directory\n",
    "ROOT_DIR = CURRENT_DIR.parents[0]  # Adjust the number based on your folder structure\n",
    "\n",
    "# Add the root directory to the system path\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "# Import the importlib module\n",
    "import importlib\n",
    "\n",
    "# import function implementations\n",
    "import stst_urls\n",
    "\n",
    "# Reload the modules\n",
    "importlib.reload(stst_urls)\n",
    "\n",
    "# Re-import the functions\n",
    "from stst_urls import QC_GTX_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Raw File and Decoder File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHY7/LIV_54_QCHY7_DNS-LIVTKCOD_LCRVCOD250-DNS_RAW20250312115454.CSV']\n"
     ]
    }
   ],
   "source": [
    "wafer_codes = [\n",
    "    \"QCHY7\",\n",
    "]  # List of wafer codes\n",
    "\n",
    "summaryfile_name = \"qchy7\"\n",
    "\n",
    "decoder_file = \"QC WAFER_LAYOUT 24Dec.csv\"\n",
    "decoder_file_path = ROOT_DIR / \"decoders\" / decoder_file\n",
    "results_file_path = ROOT_DIR / \"results\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# EXPERIMENTAL: URL fetching from GTX\n",
    "# Define the URL of the directory containing the files\n",
    "QC_GTX_URL = \"https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/\"\n",
    "\n",
    "# Fetch the directory listing\n",
    "response = requests.get(QC_GTX_URL, verify=False)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all links in the directory listing\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# Filter the links to find subdirectories that match the wafer codes\n",
    "subdirectory_urls = []\n",
    "for link in links:\n",
    "    href = link.get(\"href\")\n",
    "    if href and any(wafer_code in href for wafer_code in wafer_codes):\n",
    "        subdirectory_urls.append(QC_GTX_URL + href)\n",
    "\n",
    "# Now look inside each subdirectory for the required CSV files\n",
    "# Fetches files with COD250 and RAW in the name, with a matching wafer code\n",
    "# Also will fetch the most recent csv if there are multiple\n",
    "file_urls = []\n",
    "for subdirectory_url in subdirectory_urls:\n",
    "    response = requests.get(subdirectory_url, verify=False)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    links = soup.find_all(\"a\")\n",
    "    latest_file = None\n",
    "    latest_time = \"\"\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href and \"RAW\" in href and \"COD250\" in href:\n",
    "            time_str = href[-18:-4]  # Extract the time string\n",
    "            if time_str > latest_time:\n",
    "                latest_time = time_str\n",
    "                latest_file = subdirectory_url + href\n",
    "    if latest_file:\n",
    "        file_urls.append(latest_file)\n",
    "\n",
    "\n",
    "# print(file_paths)\n",
    "print(file_urls)\n",
    "\n",
    "# DEBUG: INPUT LINKS TO OTHER GTX FILES HERE\n",
    "# file_urls = [\n",
    "#     \"https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHWQ/LIV_53_QCHWQ_DNS-LIVTKCOD_LCRVCOD250-DNS_RAW20250227044906.CSV\",\n",
    "#     \"https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHWQ/LIV_53_QCHWQ_LIVBLTKCOD_COD250-DNS_RAW20250228082707.CSV\",\n",
    "#     \"https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHWQ/LIV_53_QCHWQ_LIVBLTKCOD_COD250-DNS_RAW20250311164324.CSV\",\n",
    "# ]\n",
    "# print(file_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Data to Desired Raw Sweep Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- selects required columns\n",
    "- transposes\n",
    "- stacks data in tall format\n",
    "- adds in device coords from decoder file\n",
    "- loops for every csv file chosen, and stores raw_sweep dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wafer ID: QCHY7\n",
      "Number of Current Measurements per Device: 250\n",
      "Number of Devices: 1288\n",
      "  WAFER_ID        Vf  TOUCHDOWN        PD   X_UM   Y_UM TE_LABEL      TYPE  \\\n",
      "0    QCHY7  1.322787          1  0.020999 -32339 -48416    64N6V  BL LASER   \n",
      "1    QCHY7  1.409667          1  0.022642 -32339 -48416    64N6V  BL LASER   \n",
      "2    QCHY7  1.448417          1  0.027571 -32339 -48416    64N6V  BL LASER   \n",
      "3    QCHY7  1.476043          1  0.019356 -32339 -48416    64N6V  BL LASER   \n",
      "4    QCHY7  1.497334          1  0.007854 -32339 -48416    64N6V  BL LASER   \n",
      "5    QCHY7  1.513642          1  0.007854 -32339 -48416    64N6V  BL LASER   \n",
      "6    QCHY7  1.529409          1  0.016070 -32339 -48416    64N6V  BL LASER   \n",
      "7    QCHY7  1.542743          1  0.020999 -32339 -48416    64N6V  BL LASER   \n",
      "8    QCHY7  1.556540          1  0.019356 -32339 -48416    64N6V  BL LASER   \n",
      "9    QCHY7  1.566436          1  0.016070 -32339 -48416    64N6V  BL LASER   \n",
      "\n",
      "   LDI_mA  \n",
      "0       1  \n",
      "1       2  \n",
      "2       3  \n",
      "3       4  \n",
      "4       5  \n",
      "5       6  \n",
      "6       7  \n",
      "7       8  \n",
      "8       9  \n",
      "9      10  \n"
     ]
    }
   ],
   "source": [
    "def transform_raw_file(file_url, decoder_file_path):\n",
    "    # Read the CSV file from the URL, skipping the first 19 rows\n",
    "    df = pd.read_csv(file_url, skiprows=19)\n",
    "    # Read the CSV file again to extract the second row\n",
    "    header_df = pd.read_csv(file_url, nrows=2)\n",
    "    # Extract the wafer id from the second row\n",
    "    wafer_id = header_df.iloc[1, 1]\n",
    "    # Print the wafer id for verification\n",
    "    print(f\"Wafer ID: {wafer_id}\")\n",
    "    # Get column names\n",
    "    col_names = df.columns\n",
    "    # Find columns containing \"Vf\" or \"PD\"\n",
    "    selected_cols = [col for col in col_names if \"Vf\" in col or \"PD\" in col]\n",
    "    # Subset the data frame with selected columns\n",
    "    df_subset = df[selected_cols]\n",
    "    # Find and delete columns containing \"Vf@\" or \"PD@\"\n",
    "    cols_to_delete = [col for col in df_subset.columns if \"Vf@\" in col or \"PD@\" in col]\n",
    "    df_subset.drop(columns=cols_to_delete, inplace=True)\n",
    "    # Transpose the data frame\n",
    "    df_transposed = df_subset.transpose()\n",
    "    # Reset index to make the transposed columns into rows\n",
    "    df_transposed.reset_index(inplace=True)\n",
    "    # Add a new row at the top with the desired titles\n",
    "    new_columns = [\"Label\"] + list(range(1, len(df_transposed.columns)))\n",
    "    df_transposed.columns = new_columns\n",
    "    df_transposed.loc[-1] = new_columns  # Add the new row at the top\n",
    "    df_transposed.index = df_transposed.index + 1  # Shift the index\n",
    "    df_transposed = df_transposed.sort_index()  # Sort by index to place the new row at the top\n",
    "    # Split transposed table into Vf and PD data tables\n",
    "    df_vf = df_transposed[df_transposed[\"Label\"].str.contains(\"Vf\")]\n",
    "    df_pd = df_transposed[df_transposed[\"Label\"].str.contains(\"PD\")]\n",
    "    # Drop the 'Label' column\n",
    "    df_vf.drop(columns=[\"Label\"], inplace=True)\n",
    "    df_pd.drop(columns=[\"Label\"], inplace=True)\n",
    "    # Learn data dimensions\n",
    "    n_meas = df_vf.shape[0]\n",
    "    print(f\"Number of Current Measurements per Device: {n_meas}\")\n",
    "    n_devices = df_vf.shape[1]\n",
    "    print(f\"Number of Devices: {n_devices}\")\n",
    "    # Concatenate all Voltage columns into one\n",
    "    df_concat_vf = pd.concat([df_vf[col] for col in df_vf.columns], ignore_index=True).to_frame(name=\"Vf\")\n",
    "    # Create TOUCHDOWN column\n",
    "    df_concat_vf[\"TOUCHDOWN\"] = [i // n_meas + 1 for i in range(n_meas * n_devices)]\n",
    "    # Concatenate all PD columns into one\n",
    "    df_concat_pd = pd.concat([df_pd[col] for col in df_pd.columns], ignore_index=True).to_frame(name=\"PD\")\n",
    "    # Cartesian join of Vf and PD data tables\n",
    "    df_raw_sweeps = pd.concat([df_concat_vf, df_concat_pd], axis=1)\n",
    "    # Add device coordinates from original RAW file\n",
    "    if \"TOUCHDOWN\" in df.columns and \"STX_WAFER_X_UM\" in df.columns and \"STX_WAFER_Y_UM\" in df.columns:\n",
    "        df_raw_sweeps = df_raw_sweeps.merge(df[[\"TOUCHDOWN\", \"STX_WAFER_X_UM\", \"STX_WAFER_Y_UM\"]], on=\"TOUCHDOWN\", how=\"left\")\n",
    "    else:\n",
    "        print(\"Required columns for merging device coordinates are missing in the original RAW file.\")\n",
    "    if decoder_file_path.exists():\n",
    "        df_decoder = pd.read_csv(decoder_file_path)\n",
    "        # Update with decoder to get TE_LABEL etc.\n",
    "        if \"YMIN\" in df_decoder.columns and \"XMIN\" in df_decoder.columns:\n",
    "            df_raw_sweeps = df_raw_sweeps.merge(\n",
    "                df_decoder[[\"YMIN\", \"XMIN\", \"TE_LABEL\", \"TYPE\"]],\n",
    "                left_on=[\"STX_WAFER_Y_UM\", \"STX_WAFER_X_UM\"],\n",
    "                right_on=[\"YMIN\", \"XMIN\"],\n",
    "                how=\"left\",\n",
    "            ).drop(columns=[\"YMIN\", \"XMIN\"])\n",
    "        else:\n",
    "            print(\"Required columns for merging decoder data are missing in the decoder file.\")\n",
    "    else:\n",
    "        print(f\"Decoder file not found at {decoder_file_path}\")\n",
    "    # Rename the columns\n",
    "    df_raw_sweeps.rename(columns={\"STX_WAFER_X_UM\": \"X_UM\", \"STX_WAFER_Y_UM\": \"Y_UM\"}, inplace=True)\n",
    "    # Add current column as a repeating sequence of length n_meas\n",
    "    df_raw_sweeps[\"LDI_mA\"] = [i % n_meas + 1 for i in range(len(df_raw_sweeps))]\n",
    "    # Add a column for WAFER_ID with the wafer_id value repeated for every row\n",
    "    df_raw_sweeps.insert(0, \"WAFER_ID\", wafer_id)\n",
    "    return df_raw_sweeps\n",
    "\n",
    "\n",
    "raw_sweeps_tables = []\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# CALLING THE CODE\n",
    "for file_url in file_urls:\n",
    "    df_raw_sweeps = transform_raw_file(file_url, decoder_file_path)\n",
    "    raw_sweeps_tables.append(df_raw_sweeps)\n",
    "\n",
    "# Display the first 10 rows of the raw_sweeps table\n",
    "print(raw_sweeps_tables[0].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
