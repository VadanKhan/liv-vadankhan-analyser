{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "\n",
    "CURRENT_DIR = Path(os.getcwd())\n",
    "# Move to the root directory\n",
    "ROOT_DIR = CURRENT_DIR.parents[0]  # Adjust the number based on your folder structure\n",
    "\n",
    "# Add the root directory to the system path\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "# Import the importlib module\n",
    "import importlib\n",
    "\n",
    "# import function implementations\n",
    "import stst_urls\n",
    "\n",
    "# Reload the modules\n",
    "importlib.reload(stst_urls)\n",
    "\n",
    "# Re-import the functions\n",
    "from stst_urls import GTX_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Raw File and Decoder File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileserver link: https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/\n",
      "['https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHY7/LIV_54_QCHY7_DNS-LIVTKCOD_LIVTK-DNS_RAW20250312110728.CSV']\n"
     ]
    }
   ],
   "source": [
    "wafer_codes = [\n",
    "    \"QCHZZ\",\n",
    "]  # List of wafer codes\n",
    "\n",
    "ANALYSIS_RUN_NAME = \"debug\"\n",
    "\n",
    "DECODER_FILE = \"QC WAFER_LAYOUT 24Dec.csv\"\n",
    "DECODER_FILE_PATH = ROOT_DIR / \"decoders\" / DECODER_FILE\n",
    "RESULTS_FILE_PATH = ROOT_DIR / \"results\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def liv_raw_filelink_finder(wafer_codes, fileserver_link: str, product_code=\"QC\"):\n",
    "    # Add the product code to the end of the fileserver link\n",
    "    fileserver_link = f\"{fileserver_link}{product_code}/\"\n",
    "    print(f\"fileserver link: {fileserver_link}\")\n",
    "\n",
    "    # Fetch the directory listing\n",
    "    response = requests.get(fileserver_link, verify=False)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all links in the directory listing\n",
    "    links = soup.find_all(\"a\")\n",
    "\n",
    "    # Filter the links to find subdirectories that match the wafer codes\n",
    "    subdirectory_urls = []\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href and any(wafer_code in href for wafer_code in wafer_codes):\n",
    "            subdirectory_urls.append(fileserver_link + href)\n",
    "\n",
    "    # Initialize lists for different types of files and a dictionary for machine names\n",
    "    file_urls = []\n",
    "    file_cod_urls = []\n",
    "    file_degradation_urls = []\n",
    "    machine_names = {}\n",
    "\n",
    "    # Iterate over wafer codes and subdirectory URLs simultaneously\n",
    "    for wafer_code, subdirectory_url in zip(wafer_codes, subdirectory_urls):\n",
    "        response = requests.get(subdirectory_url, verify=False)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        links = soup.find_all(\"a\")\n",
    "\n",
    "        latest_file = None\n",
    "        latest_cod_file = None\n",
    "        latest_degradation_file = None\n",
    "\n",
    "        latest_time = \"\"\n",
    "        latest_cod_time = \"\"\n",
    "        latest_degradation_time = \"\"\n",
    "        machine_name = None\n",
    "\n",
    "        for link in links:\n",
    "            href = link.get(\"href\")\n",
    "            if href and \"RAW\" in href:\n",
    "                time_str = href[-18:-4]  # Extract the time string\n",
    "                if not machine_name:\n",
    "                    machine_name = href[:6]  # Extract the machine name (first 6 characters)\n",
    "\n",
    "                if \"COD250\" in href:\n",
    "                    if time_str > latest_cod_time:\n",
    "                        latest_cod_time = time_str\n",
    "                        latest_cod_file = subdirectory_url + href\n",
    "                elif \"COD70\" in href:\n",
    "                    if time_str > latest_degradation_time:\n",
    "                        latest_degradation_time = time_str\n",
    "                        latest_degradation_file = subdirectory_url + href\n",
    "                else:\n",
    "                    if time_str > latest_time:\n",
    "                        latest_time = time_str\n",
    "                        latest_file = subdirectory_url + href\n",
    "\n",
    "        if latest_file:\n",
    "            file_urls.append(latest_file)\n",
    "        if latest_cod_file:\n",
    "            file_cod_urls.append(latest_cod_file)\n",
    "        if latest_degradation_file:\n",
    "            file_degradation_urls.append(latest_degradation_file)\n",
    "        if machine_name:\n",
    "            machine_names[wafer_code] = machine_name\n",
    "\n",
    "    return file_urls, file_cod_urls, file_degradation_urls, machine_names\n",
    "\n",
    "\n",
    "# print(file_paths)\n",
    "wafer_codes = [\"QCHY7\"]\n",
    "file_urls, file_cod_urls, file_degradation_urls, machine_names = liv_raw_filelink_finder(wafer_codes, GTX_URL, \"QC\")\n",
    "print(file_urls)\n",
    "\n",
    "# DEBUG: INPUT LINKS TO OTHER GTX FILES HERE\n",
    "# file_urls = [\n",
    "#     \"https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHWQ/LIV_53_QCHWQ_DNS-LIVTKCOD_LCRVCOD250-DNS_RAW20250227044906.CSV\",\n",
    "#     \"https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHWQ/LIV_53_QCHWQ_LIVBLTKCOD_COD250-DNS_RAW20250228082707.CSV\",\n",
    "#     \"https://sprgtxprod02.stni.seagate.com/~gtx/wafer/proc_LIV/data/byProdLot/QC/QCHWQ/LIV_53_QCHWQ_LIVBLTKCOD_COD250-DNS_RAW20250311164324.CSV\",\n",
    "# ]\n",
    "# print(file_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Data to Desired Raw Sweep Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- selects required columns\n",
    "- transposes\n",
    "- stacks data in tall format\n",
    "- adds in device coords from decoder file\n",
    "- loops for every csv file chosen, and stores raw_sweep dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wafer ID: QCHY7\n",
      "Number of Current Measurements per Device: 250\n",
      "Number of Devices: 1288\n",
      "Decoder file not found at c:\\Users\\762093\\OneDrive - Seagate Technology\\Documents\\LIV\\liv-vadankhan-analyser\\decoders\\QC WAFER_LAYOUT 24Dec.csv\n",
      "  WAFER_ID        Vf  TOUCHDOWN        PD   X_UM   Y_UM  LDI_mA\n",
      "0    QCHY7  1.322787          1  0.020999 -32339 -48416       1\n",
      "1    QCHY7  1.409667          1  0.022642 -32339 -48416       2\n",
      "2    QCHY7  1.448417          1  0.027571 -32339 -48416       3\n",
      "3    QCHY7  1.476043          1  0.019356 -32339 -48416       4\n",
      "4    QCHY7  1.497334          1  0.007854 -32339 -48416       5\n",
      "5    QCHY7  1.513642          1  0.007854 -32339 -48416       6\n",
      "6    QCHY7  1.529409          1  0.016070 -32339 -48416       7\n",
      "7    QCHY7  1.542743          1  0.020999 -32339 -48416       8\n",
      "8    QCHY7  1.556540          1  0.019356 -32339 -48416       9\n",
      "9    QCHY7  1.566436          1  0.016070 -32339 -48416      10\n"
     ]
    }
   ],
   "source": [
    "def transform_raw_liv_file(file_url, decoder_file_path):\n",
    "    # Read the CSV file from the URL, skipping the first 19 rows\n",
    "    df = pd.read_csv(file_url, skiprows=19)\n",
    "    # Read the CSV file again to extract the second row\n",
    "    header_df = pd.read_csv(file_url, nrows=2)\n",
    "    # Extract the wafer id from the second row\n",
    "    wafer_id = header_df.iloc[1, 1]\n",
    "    # Print the wafer id for verification\n",
    "    print(f\"Wafer ID: {wafer_id}\")\n",
    "    # Get column names\n",
    "    col_names = df.columns\n",
    "    # Find columns containing \"Vf\" or \"PD\"\n",
    "    selected_cols = [col for col in col_names if \"Vf\" in col or \"PD\" in col]\n",
    "    # Subset the data frame with selected columns\n",
    "    df_subset = df[selected_cols]\n",
    "    # Find and delete columns containing \"Vf@\" or \"PD@\"\n",
    "    cols_to_delete = [col for col in df_subset.columns if \"Vf@\" in col or \"PD@\" in col]\n",
    "    df_subset.drop(columns=cols_to_delete, inplace=True)\n",
    "    # Transpose the data frame\n",
    "    df_transposed = df_subset.transpose()\n",
    "    # Reset index to make the transposed columns into rows\n",
    "    df_transposed.reset_index(inplace=True)\n",
    "    # Add a new row at the top with the desired titles\n",
    "    new_columns = [\"Label\"] + list(range(1, len(df_transposed.columns)))\n",
    "    df_transposed.columns = new_columns\n",
    "    df_transposed.loc[-1] = new_columns  # Add the new row at the top\n",
    "    df_transposed.index = df_transposed.index + 1  # Shift the index\n",
    "    df_transposed = df_transposed.sort_index()  # Sort by index to place the new row at the top\n",
    "    # Split transposed table into Vf and PD data tables\n",
    "    df_vf = df_transposed[df_transposed[\"Label\"].str.contains(\"Vf\")]\n",
    "    df_pd = df_transposed[df_transposed[\"Label\"].str.contains(\"PD\")]\n",
    "    # Drop the 'Label' column\n",
    "    df_vf.drop(columns=[\"Label\"], inplace=True)\n",
    "    df_pd.drop(columns=[\"Label\"], inplace=True)\n",
    "    # Learn data dimensions\n",
    "    n_meas = df_vf.shape[0]\n",
    "    print(f\"Number of Current Measurements per Device: {n_meas}\")\n",
    "    n_devices = df_vf.shape[1]\n",
    "    print(f\"Number of Devices: {n_devices}\")\n",
    "    # Concatenate all Voltage columns into one\n",
    "    df_concat_vf = pd.concat([df_vf[col] for col in df_vf.columns], ignore_index=True).to_frame(name=\"Vf\")\n",
    "    # Create TOUCHDOWN column\n",
    "    df_concat_vf[\"TOUCHDOWN\"] = [i // n_meas + 1 for i in range(n_meas * n_devices)]\n",
    "    # Concatenate all PD columns into one\n",
    "    df_concat_pd = pd.concat([df_pd[col] for col in df_pd.columns], ignore_index=True).to_frame(name=\"PD\")\n",
    "    # Cartesian join of Vf and PD data tables\n",
    "    df_raw_sweeps = pd.concat([df_concat_vf, df_concat_pd], axis=1)\n",
    "    # Add device coordinates from original RAW file\n",
    "    if \"TOUCHDOWN\" in df.columns and \"STX_WAFER_X_UM\" in df.columns and \"STX_WAFER_Y_UM\" in df.columns:\n",
    "        df_raw_sweeps = df_raw_sweeps.merge(df[[\"TOUCHDOWN\", \"STX_WAFER_X_UM\", \"STX_WAFER_Y_UM\"]], on=\"TOUCHDOWN\", how=\"left\")\n",
    "    else:\n",
    "        print(\"Required columns for merging device coordinates are missing in the original RAW file.\")\n",
    "    if decoder_file_path.exists():\n",
    "        df_decoder = pd.read_csv(decoder_file_path)\n",
    "        # Update with decoder to get TE_LABEL etc.\n",
    "        if \"YMIN\" in df_decoder.columns and \"XMIN\" in df_decoder.columns:\n",
    "            df_raw_sweeps = df_raw_sweeps.merge(\n",
    "                df_decoder[[\"YMIN\", \"XMIN\", \"TE_LABEL\", \"TYPE\"]],\n",
    "                left_on=[\"STX_WAFER_Y_UM\", \"STX_WAFER_X_UM\"],\n",
    "                right_on=[\"YMIN\", \"XMIN\"],\n",
    "                how=\"left\",\n",
    "            ).drop(columns=[\"YMIN\", \"XMIN\"])\n",
    "        else:\n",
    "            print(\"Required columns for merging decoder data are missing in the decoder file.\")\n",
    "    else:\n",
    "        print(f\"Decoder file not found at {decoder_file_path}\")\n",
    "    # Rename the columns\n",
    "    df_raw_sweeps.rename(columns={\"STX_WAFER_X_UM\": \"X_UM\", \"STX_WAFER_Y_UM\": \"Y_UM\"}, inplace=True)\n",
    "    # Add current column as a repeating sequence of length n_meas\n",
    "    df_raw_sweeps[\"LDI_mA\"] = [i % n_meas + 1 for i in range(len(df_raw_sweeps))]\n",
    "    # Add a column for WAFER_ID with the wafer_id value repeated for every row\n",
    "    df_raw_sweeps.insert(0, \"WAFER_ID\", wafer_id)\n",
    "    return df_raw_sweeps\n",
    "\n",
    "\n",
    "raw_sweeps_tables = []\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# CALLING THE CODE\n",
    "for file_url in file_urls:\n",
    "    df_raw_sweeps = transform_raw_liv_file(file_url, DECODER_FILE_PATH)\n",
    "    raw_sweeps_tables.append(df_raw_sweeps)\n",
    "\n",
    "# Display the first 10 rows of the raw_sweeps table\n",
    "print(raw_sweeps_tables[0].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
